{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284e5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3166 files; accents = [1 2 3 4 5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>accent</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Train/1f_1018.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Train/1f_1026.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Train/1f_1031.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Train/1f_1070.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Train/1f_1075.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  path  accent gender\n",
       "0  ./Train/1f_1018.wav       1      f\n",
       "1  ./Train/1f_1026.wav       1      f\n",
       "2  ./Train/1f_1031.wav       1      f\n",
       "3  ./Train/1f_1070.wav       1      f\n",
       "4  ./Train/1f_1075.wav       1      f"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) all the imports you need up front\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 2) point this to wherever you unzipped the assignment's Train/ folder\n",
    "DATA_DIR = \"./Train\"  \n",
    "\n",
    "def build_metadata(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Walk through data_dir and collect file paths, accents, and genders.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for fname in sorted(files):\n",
    "            if fname.lower().endswith(\".wav\"):\n",
    "                path   = os.path.join(root, fname)\n",
    "                accent = int(fname[0])        # '1'–'5'\n",
    "                gender = fname[1].lower()     # 'm' or 'f'\n",
    "                records.append({\n",
    "                    \"path\":   path,\n",
    "                    \"accent\": accent,\n",
    "                    \"gender\": gender\n",
    "                })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Quick check\n",
    "df_meta = build_metadata(DATA_DIR)\n",
    "print(f\"Found {len(df_meta)} files; accents = {df_meta['accent'].unique()}\")\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf1f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your target sample‐rate and maximum length in samples:\n",
    "TARGET_SR = 16_000\n",
    "MAX_LEN  = 3 * TARGET_SR   # e.g. 3 seconds\n",
    "\n",
    "# transforms\n",
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=TARGET_SR,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "\n",
    "def load_and_preprocess(path: str, mode: str=\"raw\"):\n",
    "    \"\"\"Load a .wav file, resample to TARGET_SR, pad/trim to MAX_LEN, then\n",
    "       either return raw waveform [1×MAX_LEN] or mel-spec [1×n_mels×T].\"\"\"\n",
    "    wav, sr = torchaudio.load(path)           # wav: [1, L]\n",
    "    if sr != TARGET_SR:\n",
    "        wav = torchaudio.functional.resample(wav, sr, TARGET_SR)\n",
    "    # pad/trim\n",
    "    if wav.size(1) < MAX_LEN:\n",
    "        pad = MAX_LEN - wav.size(1)\n",
    "        wav = torch.nn.functional.pad(wav, (0, pad))\n",
    "    else:\n",
    "        wav = wav[:, :MAX_LEN]\n",
    "    if mode == \"raw\":\n",
    "        return wav\n",
    "    elif mode == \"mel\":\n",
    "        m = mel_transform(wav)                # [1, n_mels, T]\n",
    "        # optional: convert to log scale\n",
    "        return torch.log1p(m)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'raw' or 'mel'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b51d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccentDataset(Dataset):\n",
    "    def __init__(self, meta_df: pd.DataFrame, mode=\"raw\", accent_map=None):\n",
    "        \"\"\"\n",
    "        mode: \"raw\" or \"mel\" selects which features to compute\n",
    "        accent_map: dict mapping accents to 0…4 indices (optional)\n",
    "        \"\"\"\n",
    "        self.df   = meta_df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        # allow arbitrary accent labels 1–5 => contiguous 0–4\n",
    "        if accent_map is None:\n",
    "            labels = sorted(self.df[\"accent\"].unique())\n",
    "            self.accent_map = {lab:i for i,lab in enumerate(labels)}\n",
    "        else:\n",
    "            self.accent_map = accent_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row      = self.df.iloc[idx]\n",
    "        x        = load_and_preprocess(row[\"path\"], mode=self.mode)\n",
    "        y        = self.accent_map[row[\"accent\"]]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cd3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val\n",
    "from torch.utils.data import random_split\n",
    "full_ds = AccentDataset(df_meta, mode=\"raw\")\n",
    "n_train = int(0.8 * len(full_ds))\n",
    "n_val   = len(full_ds) - n_train\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd92008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RawCNN1D(nn.Module):\n",
    "    def __init__(self, n_classes=5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=9, stride=1, padding=4),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "\n",
    "            nn.Conv1d(16, 32, kernel_size=9, padding=4),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=9, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)    # expects x.shape = [B, 1, MAX_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6df0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelCNN2D(nn.Module):\n",
    "    def __init__(self, n_classes=5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)    # expects x.shape = [B, 1, n_mels, T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a630508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def run_experiment(model, train_loader, val_loader, epochs=10, lr=1e-3, weight_decay=1e-4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model  = model.to(device)\n",
    "    opt    = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    crit   = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # ——— train ———\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss   = crit(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "        history[\"train_loss\"].append(total_loss / len(train_loader.dataset))\n",
    "\n",
    "        # ——— eval ———\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                total_loss += crit(logits, y).item() * x.size(0)\n",
    "                preds = logits.argmax(dim=1).cpu().tolist()\n",
    "                all_preds.extend(preds)\n",
    "                all_targets.extend(y.cpu().tolist())\n",
    "\n",
    "        val_loss = total_loss / len(val_loader.dataset)\n",
    "        val_acc  = accuracy_score(all_targets, all_preds)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | Train loss: {history['train_loss'][-1]:.4f} \"\n",
    "              f\"| Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee91d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train loss: 1.5311 | Val loss: 1.4905 | Val acc: 0.3454\n",
      "Epoch 02 | Train loss: 1.4048 | Val loss: 1.5587 | Val acc: 0.2918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_loader   \u001b[38;5;241m=\u001b[39m DataLoader(val_ds,   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m      8\u001b[0m raw_model \u001b[38;5;241m=\u001b[39m RawCNN1D(n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m raw_model, raw_hist \u001b[38;5;241m=\u001b[39m run_experiment(raw_model, train_loader, val_loader,\n\u001b[1;32m     10\u001b[0m                                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model, train_loader, val_loader, epochs, lr, weight_decay)\u001b[0m\n\u001b[1;32m     17\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     20\u001b[0m loss   \u001b[38;5;241m=\u001b[39m crit(logits, y)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mRawCNN1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    372\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Raw-waveform experiment\n",
    "raw_ds  = AccentDataset(df_meta, mode=\"raw\")\n",
    "n_train = int(0.8*len(raw_ds))\n",
    "train_ds, val_ds = random_split(raw_ds, [n_train, len(raw_ds)-n_train])\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32)\n",
    "\n",
    "raw_model = RawCNN1D(n_classes=5)\n",
    "raw_model, raw_hist = run_experiment(raw_model, train_loader, val_loader,\n",
    "                                     epochs=5, lr=1e-3)\n",
    "\n",
    "# Mel-spectrogram experiment\n",
    "# mel_ds = AccentDataset(df_meta, mode=\"mel\", accent_map=raw_ds.accent_map)\n",
    "# train_ds, val_ds = random_split(mel_ds, [n_train, len(mel_ds)-n_train])\n",
    "# train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "# val_loader   = DataLoader(val_ds,   batch_size=32)\n",
    "\n",
    "# mel_model, mel_hist = run_experiment(MelCNN2D(5), train_loader, val_loader,\n",
    "#                                      epochs=15, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcd7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
