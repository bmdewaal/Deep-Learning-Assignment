{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416bf165",
   "metadata": {},
   "source": [
    "# Task 1 - Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f93f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "from glob import glob\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecd2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Dataset + helpers\n",
    "\n",
    "class AccentAudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lazily loads .wav files and extracts accent & gender from filename.\n",
    "    Filenames like '3f_utterance123.wav' where:\n",
    "      - first char = accent [1-5]\n",
    "      - second char = gender 'm' or 'f'\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.filepaths = sorted(glob(os.path.join(data_dir, '*.wav')))\n",
    "        if not self.filepaths:\n",
    "            raise RuntimeError(f\"[AccentAudioDataset] No .wav files in {data_dir!r}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.filepaths[idx]\n",
    "        waveform, sr = torchaudio.load(path)          # [1, L]\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "        # online standardization\n",
    "        waveform = (waveform - waveform.mean()) / (waveform.std() + 1e-9)\n",
    "        fname = os.path.basename(path)\n",
    "        accent = int(fname[0]) - 1                   # 0–4\n",
    "        gender = 0 if fname[1] == 'm' else 1\n",
    "        return waveform.squeeze(0), accent, gender\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\" Pad to batch-max length, return lengths + labels \"\"\"\n",
    "    waves, accents, genders = zip(*batch)\n",
    "    lengths = torch.tensor([w.size(0) for w in waves], dtype=torch.long)\n",
    "    padded  = pad_sequence(waves, batch_first=True)\n",
    "    return padded, lengths, torch.tensor(accents), torch.tensor(genders)\n",
    "\n",
    "def compute_dataset_stats(data_dir, sample_rate=16000):\n",
    "    \"\"\" Scan WAVs for duration stats; errors if folder’s empty \"\"\"\n",
    "    paths = glob(os.path.join(data_dir, '*.wav'))\n",
    "    if not paths:\n",
    "        raise RuntimeError(f\"[compute_dataset_stats] No .wav files in {data_dir!r}\")\n",
    "    durations = torch.tensor([torchaudio.info(p).num_frames / sample_rate for p in paths])\n",
    "    return {\n",
    "        'count': len(durations),\n",
    "        'min_s':  float(durations.min()),\n",
    "        'max_s':  float(durations.max()),\n",
    "        'mean_s': float(durations.mean()),\n",
    "        'p90_s':  float(durations.kthvalue(int(0.9*len(durations))).values)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec885ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DIR: /Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Train → exists? True\n",
      "  sample files: ['2m_9039.wav', '4f_1887.wav', '4f_9571.wav', '1m_3736.wav', '1m_3078.wav']\n",
      " TEST_DIR: /Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Test → exists? True\n",
      "  sample files: ['9430.wav', '4458.wav', '1534.wav', '8510.wav', '7192.wav']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Point to your folders & verify\n",
    "# ↳ Copy paths exactly, no trailing spaces ↓\n",
    "TRAIN_DIR = \"/Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Train\"\n",
    "TEST_DIR  = \"/Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Test\"\n",
    "\n",
    "# Strip accidental whitespace just in case\n",
    "TRAIN_DIR = TRAIN_DIR.strip()\n",
    "TEST_DIR  = TEST_DIR.strip()\n",
    "\n",
    "print(\"TRAIN_DIR:\", TRAIN_DIR, \"→ exists?\", os.path.isdir(TRAIN_DIR))\n",
    "print(\"  sample files:\", os.listdir(TRAIN_DIR)[:5])\n",
    "print(\" TEST_DIR:\", TEST_DIR, \"→ exists?\", os.path.isdir(TEST_DIR))\n",
    "print(\"  sample files:\", os.listdir(TEST_DIR)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379261aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1a: Monkey-patch gender parsing in existing AccentAudioDataset\n",
    "\n",
    "# Fetch original class\n",
    "OrigDataset = AccentAudioDataset\n",
    "\n",
    "# Create a subclass to override only gender logic\n",
    "class FixedAccentAudioDataset(OrigDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, accent, gender = super().__getitem__(idx)\n",
    "        # re-parse gender from filename case-insensitive\n",
    "        fname = os.path.basename(self.filepaths[idx])\n",
    "        gender_char = fname[1].lower()\n",
    "        if gender_char == 'm':\n",
    "            gender = 0\n",
    "        elif gender_char == 'f':\n",
    "            gender = 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized gender '{fname[1]}'\")\n",
    "        return waveform, accent, gender\n",
    "\n",
    "# Replace dataset class\n",
    "AccentAudioDataset = FixedAccentAudioDataset\n",
    "\n",
    "# Recreate loaders without re-importing torchaudio\n",
    "train_ds = AccentAudioDataset(TRAIN_DIR)\n",
    "test_ds  = AccentAudioDataset(TEST_DIR)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, collate_fn=collate_fn, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfb1f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch → waves: torch.Size([32, 141994]), lengths: torch.Size([32])\n",
      "Test batch → waves: torch.Size([32, 150186]), lengths: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 (fast sanity check): instantiate datasets, build loaders & grab one batch\n",
    "\n",
    "# 1) Instantiate datasets\n",
    "train_ds = AccentAudioDataset(TRAIN_DIR)\n",
    "test_ds  = AccentAudioDataset(TEST_DIR)\n",
    "\n",
    "# 2) Create DataLoaders with num_workers=0 to avoid spawn overhead in Jupyter\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,       # no worker processes\n",
    "    pin_memory=False,    # lower overhead in notebook\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# 3) Sanity-check one batch from each loader\n",
    "for name, loader in [(\"Train\", train_loader), (\"Test\", test_loader)]:\n",
    "    waves, lengths, accents, genders = next(iter(loader))\n",
    "    print(f\"{name} batch → waves: {waves.shape}, lengths: {lengths.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132bc6d",
   "metadata": {},
   "source": [
    "# Task 2 - Raw signal 1d cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed42808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Raw-Signal 1D CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RawCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    1D CNN for raw waveform classification (5 accents).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=5, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Conv stage 1: 1→16 channels, downsample by 4\n",
    "            nn.Conv1d(1, 16, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),  # seq_len / 4 total\n",
    "\n",
    "            # Conv stage 2: 16→32, downsample by 2\n",
    "            nn.Conv1d(16, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),  # seq_len / 8 total\n",
    "\n",
    "            # Conv stage 3: 32→64, downsample by 2\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),  # seq_len / 16 total\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1),  # collapse time dim\n",
    "            nn.Flatten(),             # → [B, 64]\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: FloatTensor [B, T] raw wave\n",
    "        \"\"\"\n",
    "        # add channel dim\n",
    "        x = x.unsqueeze(1)  # [B,1,T]\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c140765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "✅ RawCNN forward pass on mps OK: torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Device selection & forward pass test (using MPS if available)\n",
    "\n",
    "import torch\n",
    "\n",
    "# 1) Select device: MPS (Apple GPU) if available, else CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2) Move model to device\n",
    "model = RawCNN(num_classes=5, dropout=0.2).to(device)\n",
    "model.eval()\n",
    "\n",
    "# 3) Grab one batch, move to device, and test forward pass\n",
    "with torch.no_grad():\n",
    "    waves, lengths, accents, genders = next(iter(train_loader))\n",
    "    waves = waves.to(device)\n",
    "    logits = model(waves)\n",
    "    assert logits.shape == (waves.size(0), 5), f\"Expected [B,5], got {logits.shape}\"\n",
    "    print(f\"✅ RawCNN forward pass on {device} OK: {logits.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcfb5c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   → loss: 1.5678, acc: 0.297, time: 17.8s\n",
      "Validate→ loss: 0.8872, acc: 0.105\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training & Evaluation Functions with MPS Support\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "    for waves, lengths, accents, _ in loader:\n",
    "        waves, accents = waves.to(device), accents.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(waves)\n",
    "        loss = F.cross_entropy(logits, accents)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * waves.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == accents).sum().item()\n",
    "        total += waves.size(0)\n",
    "    elapsed = time.time() - start\n",
    "    return total_loss / total, correct / total, elapsed\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for waves, lengths, accents, _ in loader:\n",
    "        waves, accents = waves.to(device), accents.to(device)\n",
    "        logits = model(waves)\n",
    "        loss = F.cross_entropy(logits, accents)\n",
    "\n",
    "        total_loss += loss.item() * waves.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == accents).sum().item()\n",
    "        total += waves.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# Quick function test (one batch)\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = RawCNN(num_classes=5, dropout=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_loss, train_acc, train_time = train_one_epoch(model, train_loader, optimizer, device)\n",
    "val_loss,   val_acc   = evaluate(model, test_loader, device)\n",
    "print(f\"Train   → loss: {train_loss:.4f}, acc: {train_acc:.3f}, time: {train_time:.1f}s\")\n",
    "print(f\"Validate→ loss: {val_loss:.4f}, acc: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95dc0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_report(model, loader, device):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for waves, lengths, accents, genders in loader:\n",
    "            waves = waves.to(device)\n",
    "            logits = model(waves)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(accents.numpy())\n",
    "            all_genders.append(genders.numpy())\n",
    "\n",
    "    all_preds   = np.concatenate(all_preds)\n",
    "    all_labels  = np.concatenate(all_labels)\n",
    "    all_genders = np.concatenate(all_genders)\n",
    "\n",
    "    labels       = [0, 1, 2, 3, 4]\n",
    "    target_names = [f\"Accent {i}\" for i in range(1, 6)]\n",
    "\n",
    "    print(\"Classification Report (Accents):\")\n",
    "    print(classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        labels=labels,\n",
    "        target_names=target_names,\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f71af6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.5783, Acc: 0.283 | Val   Loss: 1.5457, Acc: 0.329 | Time: 29.9s\n",
      "Epoch 02 | Train Loss: 1.5294, Acc: 0.352 | Val   Loss: 1.5066, Acc: 0.395 | Time: 36.8s\n",
      "Epoch 03 | Train Loss: 1.4947, Acc: 0.383 | Val   Loss: 1.4795, Acc: 0.392 | Time: 47.5s\n",
      "Epoch 04 | Train Loss: 1.4527, Acc: 0.409 | Val   Loss: 1.4466, Acc: 0.414 | Time: 38.2s\n",
      "Epoch 05 | Train Loss: 1.4241, Acc: 0.421 | Val   Loss: 1.4030, Acc: 0.471 | Time: 35.5s\n",
      "\n",
      "Final Validation Set Metrics:\n",
      "Classification Report (Accents):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Accent 1       0.74      0.79      0.76       146\n",
      "    Accent 2       0.34      0.27      0.30       126\n",
      "    Accent 3       0.00      0.00      0.00       113\n",
      "    Accent 4       0.39      0.78      0.52       156\n",
      "    Accent 5       0.43      0.30      0.36        92\n",
      "\n",
      "    accuracy                           0.47       633\n",
      "   macro avg       0.38      0.43      0.39       633\n",
      "weighted avg       0.40      0.47      0.42       633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Full Training Loop with Scheduler & Early Stopping (using val_loader)\n",
    "\n",
    "num_epochs = 5\n",
    "patience = 2\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Ensure you're using the RawCNN model and its optimizer\n",
    "model_raw     = RawCNN(num_classes=5, dropout=0.3).to(device)\n",
    "optimizer_raw = torch.optim.Adam(model_raw.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler_raw = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_raw, mode='min', factor=0.5, patience=1\n",
    ")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # — Training on train_loader —\n",
    "    tr_loss, tr_acc, tr_time = train_one_epoch(\n",
    "        model_raw, train_loader, optimizer_raw, device\n",
    "    )\n",
    "    # — Validation on val_loader —\n",
    "    vl_loss, vl_acc = evaluate(\n",
    "        model_raw, val_loader, device\n",
    "    )\n",
    "    # Scheduler step on validation loss\n",
    "    scheduler_raw.step(vl_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.3f} | \"\n",
    "          f\"Val   Loss: {vl_loss:.4f}, Acc: {vl_acc:.3f} | \"\n",
    "          f\"Time: {tr_time:.1f}s\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if vl_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = vl_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve > patience:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# After training, run your detailed report on validation set\n",
    "print(\"\\nFinal Validation Set Metrics:\")\n",
    "evaluate_and_report(model_raw, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b440833",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2291932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Spectrogram CNN Definition & Forward Test\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# # Forward‐pass test on MPS/CPU\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "# model = SpectrogramCNN().to(device)\n",
    "# with torch.no_grad():\n",
    "#     specs = specs.to(device)\n",
    "#     logits = model(specs)\n",
    "#     print(\"✅ SpectrogramCNN forward:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f0dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpecTrain batch: torch.Size([32, 1, 64, 486]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 9 (replace your old Spectrogram DataLoader cell) ──\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 1) Build the full SpectrogramDataset over your TRAIN_DIR\n",
    "spec_full_ds = SpectrogramDataset(TRAIN_DIR, mel_transform)\n",
    "\n",
    "# 2) Carve out the same 80/20 split you used for raw-wave data\n",
    "#    `train_ds` and `val_ds` are Subset objects over the raw AccentAudioDataset\n",
    "#    and they carry `.indices` into the file list. We reuse those here.\n",
    "spec_train_ds = Subset(spec_full_ds, train_ds.indices)\n",
    "spec_val_ds   = Subset(spec_full_ds, val_ds.indices)\n",
    "\n",
    "# 3) DataLoaders\n",
    "spec_train_loader = DataLoader(\n",
    "    spec_train_ds, batch_size=32, shuffle=True,\n",
    "    num_workers=0, pin_memory=False,\n",
    "    collate_fn=spectrogram_collate_fn\n",
    ")\n",
    "spec_val_loader = DataLoader(\n",
    "    spec_val_ds, batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=False,\n",
    "    collate_fn=spectrogram_collate_fn\n",
    ")\n",
    "\n",
    "# 4) Sanity check\n",
    "batch = next(iter(spec_train_loader))\n",
    "print(\"SpecTrain batch:\", batch[0].shape, batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27169fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SpectrogramCNN forward on spec_train_loader OK: torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Spectrogram CNN Definition & Forward Test\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ── Cell 10 (replace your old SpectrogramCNN one-batch test) ──\n",
    "\n",
    "model_spec = SpectrogramCNN(num_classes=5, dropout=0.3).to(device)\n",
    "model_spec.eval()\n",
    "with torch.no_grad():\n",
    "    specs, lengths, accents, genders = next(iter(spec_train_loader))\n",
    "    specs = specs.to(device)\n",
    "    logits = model_spec(specs)\n",
    "    assert logits.shape == (specs.size(0), 5), logits.shape\n",
    "print(\"✅ SpectrogramCNN forward on spec_train_loader OK:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a73262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "SpectrogramCNN → Train loss: 1.5469, acc: 0.315\n",
      "                 Val   loss: 0.9278, acc: 0.109\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Train & Eval SpectrogramCNN on MPS/CPU (one‐batch smoke test)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1) Device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2) Instantiate model, optimizer\n",
    "model_spec = SpectrogramCNN(num_classes=5, dropout=0.3).to(device)\n",
    "optimizer_spec = optim.Adam(model_spec.parameters(), lr=1e-3)\n",
    "\n",
    "# 3) Quick one‐batch train & eval\n",
    "train_loss, train_acc, _ = train_one_epoch(model_spec, spec_train_loader, optimizer_spec, device)\n",
    "val_loss,   val_acc       = evaluate   (model_spec, spec_test_loader,        device)\n",
    "\n",
    "print(f\"SpectrogramCNN → Train loss: {train_loss:.4f}, acc: {train_acc:.3f}\")\n",
    "print(f\"                 Val   loss: {val_loss:.4f}, acc: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76c44fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3166 samples → 2533 train, 633 val\n"
     ]
    }
   ],
   "source": [
    "# Cell X: Create train/val split for local evaluation\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Full dataset on the labeled Train folder\n",
    "full_ds = AccentAudioDataset(TRAIN_DIR)\n",
    "\n",
    "# 80/20 split\n",
    "n = len(full_ds)\n",
    "n_val = int(0.2 * n)\n",
    "n_train = n - n_val\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,\n",
    "                          num_workers=0, pin_memory=False, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False,\n",
    "                          num_workers=0, pin_memory=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Split {n} samples → {n_train} train, {n_val} val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47735cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Acc: 0.325, Val Acc: 0.259 | Time: 18.2s\n",
      "Epoch 02 | Train Acc: 0.393, Val Acc: 0.355 | Time: 10.5s\n",
      "Epoch 03 | Train Acc: 0.450, Val Acc: 0.479 | Time: 12.0s\n",
      "Epoch 04 | Train Acc: 0.487, Val Acc: 0.482 | Time: 10.2s\n",
      "Epoch 05 | Train Acc: 0.527, Val Acc: 0.523 | Time: 11.5s\n",
      "\n",
      "Final SpectrogramCNN on val set:\n",
      "Classification Report (Accents):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Accent 1       1.00      0.60      0.75       146\n",
      "    Accent 2       0.49      0.73      0.58       126\n",
      "    Accent 3       0.79      0.10      0.17       113\n",
      "    Accent 4       0.43      0.88      0.58       156\n",
      "    Accent 5       0.12      0.03      0.05        92\n",
      "\n",
      "    accuracy                           0.52       633\n",
      "   macro avg       0.56      0.47      0.43       633\n",
      "weighted avg       0.59      0.52      0.47       633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 11 (replace your old SpectrogramCNN full-training loop) ──\n",
    "\n",
    "optimizer_spec = torch.optim.Adam(model_spec.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler_spec = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_spec, mode='min', factor=0.5, patience=1\n",
    ")\n",
    "\n",
    "best_val, no_improve = float('inf'), 0\n",
    "for epoch in range(1, 6):\n",
    "    tr_loss, tr_acc, tr_time = train_one_epoch(\n",
    "        model_spec, spec_train_loader, optimizer_spec, device\n",
    "    )\n",
    "    vl_loss, vl_acc = evaluate(\n",
    "        model_spec, spec_val_loader, device\n",
    "    )\n",
    "    scheduler_spec.step(vl_loss)\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Acc: {tr_acc:.3f}, Val Acc: {vl_acc:.3f} | \"\n",
    "          f\"Time: {tr_time:.1f}s\")\n",
    "    if vl_loss < best_val - 1e-4:\n",
    "        best_val, no_improve = vl_loss, 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve > 2:\n",
    "            print(\"⏹ Early stopping\")\n",
    "            break\n",
    "\n",
    "print(\"\\nFinal SpectrogramCNN on val set:\")\n",
    "evaluate_and_report(model_spec, spec_val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03baeb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.4304, Acc: 0.437 | Val   Loss: 0.9086, Acc: 0.120 | Time: 18.7s\n",
      "Epoch 02 | Train Loss: 1.3113, Acc: 0.505 | Val   Loss: 0.9614, Acc: 0.118 | Time: 18.1s\n",
      "Epoch 03 | Train Loss: 1.2123, Acc: 0.543 | Val   Loss: 0.9655, Acc: 0.114 | Time: 13.3s\n",
      "Epoch 04 | Train Loss: 1.1359, Acc: 0.582 | Val   Loss: 0.9930, Acc: 0.114 | Time: 12.9s\n",
      "⏹ Early stopping at epoch 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Full Training Loop for SpectrogramCNN with Scheduler & Early Stopping\n",
    "\n",
    "num_epochs = 5\n",
    "patience = 2\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Prepare model, optimizer, scheduler\n",
    "model_raw = RawCNN(num_classes=5, dropout=0.3).to(device)\n",
    "optimizer_raw = torch.optim.Adam(model_raw.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler_raw = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_raw, mode='min', factor=0.5, patience=1\n",
    ")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train on training split\n",
    "    tr_loss, tr_acc, tr_time = train_one_epoch(model_raw, train_loader, optimizer_raw, device)\n",
    "    # Validate on validation split\n",
    "    vl_loss, vl_acc = evaluate(model_raw, val_loader, device)\n",
    "    # Step scheduler\n",
    "    scheduler_raw.step(vl_loss)\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.3f} | \"\n",
    "          f\"Val   Loss: {vl_loss:.4f}, Acc: {vl_acc:.3f} | \"\n",
    "          f\"Time: {tr_time:.1f}s\")\n",
    "    # Early stopping\n",
    "    if vl_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = vl_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve > patience:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# After training, print detailed validation report\n",
    "print(\"\\nValidation Set Results:\")\n",
    "evaluate_and_report(model_raw, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0255d",
   "metadata": {},
   "source": [
    "# Task 3 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6f40232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do=0.1, wd=0.0 → val_acc=0.622\n",
      "do=0.1, wd=0.0001 → val_acc=0.608\n",
      "do=0.1, wd=0.001 → val_acc=0.485\n",
      "do=0.3, wd=0.0 → val_acc=0.532\n",
      "do=0.3, wd=0.0001 → val_acc=0.551\n",
      "do=0.3, wd=0.001 → val_acc=0.551\n",
      "do=0.5, wd=0.0 → val_acc=0.474\n",
      "do=0.5, wd=0.0001 → val_acc=0.539\n",
      "do=0.5, wd=0.001 → val_acc=0.458\n",
      "   dropout      wd   val_acc\n",
      "0      0.1  0.0000  0.622433\n",
      "1      0.1  0.0001  0.608215\n",
      "2      0.1  0.0010  0.484992\n",
      "3      0.3  0.0000  0.532385\n",
      "4      0.3  0.0001  0.551343\n",
      "5      0.3  0.0010  0.551343\n",
      "6      0.5  0.0000  0.473934\n",
      "7      0.5  0.0001  0.538705\n",
      "8      0.5  0.0010  0.458136\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 13 (replace your old Spec-regularization sweep) ──\n",
    "\n",
    "import itertools\n",
    "import torch.optim as optim\n",
    "\n",
    "results = []\n",
    "for do, wd in itertools.product([0.1,0.3,0.5], [0.0,1e-4,1e-3]):\n",
    "    # instantiate\n",
    "    m = SpectrogramCNN(num_classes=5, dropout=do).to(device)\n",
    "    opt = optim.Adam(m.parameters(), lr=1e-3, weight_decay=wd)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=1)\n",
    "    # train w/ early stop\n",
    "    best, no_imp = float('inf'), 0\n",
    "    for _ in range(5):\n",
    "        train_one_epoch(m, spec_train_loader, opt, device)\n",
    "        vl_loss, vl_acc = evaluate(m, spec_val_loader, device)\n",
    "        sched.step(vl_loss)\n",
    "        if vl_loss < best - 1e-4:\n",
    "            best, no_imp = vl_loss, 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "            if no_imp > 2: break\n",
    "    results.append({'dropout':do, 'wd':wd, 'val_acc':vl_acc})\n",
    "    print(f\"do={do}, wd={wd} → val_acc={vl_acc:.3f}\")\n",
    "\n",
    "import pandas as pd\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6431be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RawCNN] Epoch 01 | Train Loss: 1.5761, Acc: 0.292 | Val   Loss: 1.5535, Acc: 0.344 | Time: 57.1s\n",
      "[RawCNN] Epoch 02 | Train Loss: 1.5136, Acc: 0.379 | Val   Loss: 1.4898, Acc: 0.423 | Time: 36.8s\n",
      "[RawCNN] Epoch 03 | Train Loss: 1.4669, Acc: 0.415 | Val   Loss: 1.4558, Acc: 0.414 | Time: 45.7s\n",
      "[RawCNN] Epoch 04 | Train Loss: 1.4131, Acc: 0.438 | Val   Loss: 1.4052, Acc: 0.415 | Time: 39.0s\n",
      "[RawCNN] Epoch 05 | Train Loss: 1.3682, Acc: 0.460 | Val   Loss: 1.3428, Acc: 0.482 | Time: 33.9s\n",
      "✔️ Finished RawCNN training: best val_acc = 0.482\n",
      "\n",
      "Validation Set Metrics for RawCNN:\n",
      "Classification Report (Accents):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Accent 1       0.60      0.96      0.74       146\n",
      "    Accent 2       0.45      0.20      0.27       126\n",
      "    Accent 3       0.75      0.03      0.05       113\n",
      "    Accent 4       0.39      0.79      0.52       156\n",
      "    Accent 5       0.61      0.15      0.24        92\n",
      "\n",
      "    accuracy                           0.48       633\n",
      "   macro avg       0.56      0.42      0.37       633\n",
      "weighted avg       0.55      0.48      0.40       633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 (updated): Train RawCNN with Best Regularization & Early Stopping\n",
    "# — now evaluating on val_loader —\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Hyperparams from SpectrogramCNN grid: dropout=0.1, weight_decay=0.0 (best val_acc=0.622)\n",
    "model_raw     = RawCNN(num_classes=5, dropout=0.1).to(device)\n",
    "optimizer_raw = optim.Adam(model_raw.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "scheduler_raw = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_raw, mode='min', factor=0.5, patience=1\n",
    ")\n",
    "\n",
    "num_epochs   = 5\n",
    "patience     = 2\n",
    "best_val     = float('inf')\n",
    "no_improve   = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    t0 = time.time()\n",
    "    # Train on the training split\n",
    "    tr_loss, tr_acc, tr_time = train_one_epoch(\n",
    "        model_raw, train_loader, optimizer_raw, device\n",
    "    )\n",
    "    # Validate on the validation split\n",
    "    vl_loss, vl_acc = evaluate(\n",
    "        model_raw, val_loader, device\n",
    "    )\n",
    "    scheduler_raw.step(vl_loss)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(f\"[RawCNN] Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.3f} | \"\n",
    "          f\"Val   Loss: {vl_loss:.4f}, Acc: {vl_acc:.3f} | \"\n",
    "          f\"Time: {dt:.1f}s\")\n",
    "\n",
    "    # Early stopping\n",
    "    if vl_loss < best_val - 1e-4:\n",
    "        best_val, no_improve = vl_loss, 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve > patience:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"✔️ Finished RawCNN training: best val_acc = {vl_acc:.3f}\")\n",
    "\n",
    "# Final detailed report on the validation set\n",
    "print(\"\\nValidation Set Metrics for RawCNN:\")\n",
    "evaluate_and_report(model_raw, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd785dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized gender '0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: N/A (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Run it:\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m evaluate_and_report(model_raw, test_loader, device)\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mevaluate_and_report\u001b[0;34m(model, loader, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m all_preds, all_labels, all_genders \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m waves, lengths, accents, genders \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     11\u001b[0m         waves \u001b[38;5;241m=\u001b[39m waves\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m         logits \u001b[38;5;241m=\u001b[39m model(waves)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m, in \u001b[0;36mFixedAccentAudioDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m     gender \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized gender \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m waveform, accent, gender\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized gender '0'"
     ]
    }
   ],
   "source": [
    "# # Cell 15: Detailed Performance Evaluation by Accent & Gender (fully self-contained)\n",
    "\n",
    "# def evaluate_and_report(model, loader, device):\n",
    "#     import numpy as np\n",
    "#     from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#     model.eval()\n",
    "#     all_preds, all_labels, all_genders = [], [], []\n",
    "#     with torch.no_grad():\n",
    "#         for waves, lengths, accents, genders in loader:\n",
    "#             waves = waves.to(device)\n",
    "#             logits = model(waves)\n",
    "#             preds = logits.argmax(dim=1).cpu().numpy()\n",
    "#             all_preds.append(preds)\n",
    "#             all_labels.append(accents.numpy())\n",
    "#             all_genders.append(genders.numpy())\n",
    "\n",
    "#     all_preds   = np.concatenate(all_preds)\n",
    "#     all_labels  = np.concatenate(all_labels)\n",
    "#     all_genders = np.concatenate(all_genders)\n",
    "\n",
    "#     labels       = [0, 1, 2, 3, 4]\n",
    "#     target_names = [f\"Accent {i}\" for i in range(1, 6)]\n",
    "\n",
    "#     print(\"Classification Report (Accents):\")\n",
    "#     print(classification_report(\n",
    "#         all_labels,\n",
    "#         all_preds,\n",
    "#         labels=labels,\n",
    "#         target_names=target_names,\n",
    "#         zero_division=0\n",
    "#     ))\n",
    "\n",
    "#     print(\"\\nConfusion Matrix:\")\n",
    "#     print(confusion_matrix(all_labels, all_preds, labels=labels))\n",
    "\n",
    "#     print(\"\\nGender-specific accuracy:\")\n",
    "#     for val, name in zip([0, 1], [\"Male\", \"Female\"]):\n",
    "#         idxs = all_genders == val\n",
    "#         count = idxs.sum()\n",
    "#         if count > 0:\n",
    "#             acc = (all_preds[idxs] == all_labels[idxs]).mean()\n",
    "#             print(f\"  {name}: {acc:.3f} ({count} samples)\")\n",
    "#         else:\n",
    "#             print(f\"  {name}: N/A ({count} samples)\")\n",
    "\n",
    "# # Run it:\n",
    "# evaluate_and_report(model_raw, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264ea7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Define SpecAugment masks\n",
    "from torchaudio.transforms import FrequencyMasking, TimeMasking\n",
    "\n",
    "freq_mask = FrequencyMasking(freq_mask_param=15)  # mask up to 15 mel bins\n",
    "time_mask = TimeMasking(time_mask_param=35)       # mask up to 35 time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea965c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented spec batch: torch.Size([16, 1, 64, 550]) lengths: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Build SpecAugmented train loader (val loader stays un-augmented)\n",
    "class SpecAugmentedDataset(SpectrogramDataset):\n",
    "    def __init__(self, data_dir, mel_transform, masks):\n",
    "        super().__init__(data_dir, mel_transform)\n",
    "        self.masks = masks\n",
    "    def __getitem__(self, idx):\n",
    "        spec, accent, gender = super().__getitem__(idx)\n",
    "        for m in self.masks:\n",
    "            spec = m(spec)\n",
    "        return spec, accent, gender\n",
    "\n",
    "# Create dataset & loader on the TRAIN split indices\n",
    "from torch.utils.data import Subset\n",
    "spec_full_ds      = SpectrogramDataset(TRAIN_DIR, mel_transform)\n",
    "spec_aug_train_ds = Subset(spec_full_ds, train_ds.indices)\n",
    "spec_aug_train_ds.dataset = SpecAugmentedDataset(TRAIN_DIR, mel_transform, [freq_mask, time_mask])\n",
    "spec_aug_train_loader = DataLoader(\n",
    "    spec_aug_train_ds, batch_size=16, shuffle=True,\n",
    "    num_workers=0, pin_memory=False, collate_fn=spectrogram_collate_fn\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "batch = next(iter(spec_aug_train_loader))\n",
    "print(\"Augmented spec batch:\", batch[0].shape, \"lengths:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72b42ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpecAugment → train_acc: 0.308, val_acc: 0.340\n"
     ]
    }
   ],
   "source": [
    "# Cell 18 (fixed): One‐batch train/eval with SpecAugment\n",
    "\n",
    "model_sa = SpectrogramCNN(num_classes=5, dropout=0.1).to(device)\n",
    "opt_sa   = torch.optim.Adam(model_sa.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "\n",
    "# Train on SpecAugmented train split\n",
    "train_loss_sa, train_acc_sa, _ = train_one_epoch(model_sa, spec_aug_train_loader, opt_sa, device)\n",
    "# Validate on SpecAugmented val split\n",
    "val_loss_sa,   val_acc_sa       = evaluate(model_sa, spec_val_loader, device)\n",
    "\n",
    "print(f\"SpecAugment → train_acc: {train_acc_sa:.3f}, val_acc: {val_acc_sa:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc427ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_acc: 0.379 | val_acc: 0.336\n",
      "Epoch 02 | train_acc: 0.437 | val_acc: 0.401\n",
      "Epoch 03 | train_acc: 0.465 | val_acc: 0.419\n",
      "Epoch 04 | train_acc: 0.485 | val_acc: 0.414\n",
      "Epoch 05 | train_acc: 0.510 | val_acc: 0.529\n",
      "\n",
      "Validation Set Metrics for SpecAugment:\n",
      "Classification Report (Accents):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Accent 1       0.94      0.80      0.86       146\n",
      "    Accent 2       0.32      0.97      0.48       126\n",
      "    Accent 3       0.00      0.00      0.00       113\n",
      "    Accent 4       0.94      0.53      0.67       156\n",
      "    Accent 5       0.33      0.15      0.21        92\n",
      "\n",
      "    accuracy                           0.53       633\n",
      "   macro avg       0.51      0.49      0.45       633\n",
      "weighted avg       0.56      0.53      0.49       633\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117  23   0   0   6]\n",
      " [  2 122   0   0   2]\n",
      " [  1  98   0   0  14]\n",
      " [  0  67   0  82   7]\n",
      " [  5  68   0   5  14]]\n",
      "\n",
      "Gender-specific accuracy:\n",
      "  Male: 0.475 (295 samples)\n",
      "  Female: 0.577 (338 samples)\n"
     ]
    }
   ],
   "source": [
    "# Cell 19 (fixed): Full 5‐epoch loop w/ early stopping (SpecAugment → spec_val_loader)\n",
    "\n",
    "scheduler_sa = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_sa, mode='min', factor=0.5, patience=1)\n",
    "best_val, no_improve = float('inf'), 0\n",
    "\n",
    "for ep in range(1, 6):\n",
    "    tr_loss, tr_acc, _ = train_one_epoch(model_sa, spec_aug_train_loader, opt_sa, device)\n",
    "    vl_loss, vl_acc    = evaluate(model_sa, spec_val_loader, device)\n",
    "    scheduler_sa.step(vl_loss)\n",
    "    print(f\"Epoch {ep:02d} | train_acc: {tr_acc:.3f} | val_acc: {vl_acc:.3f}\")\n",
    "    if vl_loss < best_val - 1e-4:\n",
    "        best_val, no_improve = vl_loss, 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve > 2:\n",
    "            print(\"⏹ Early stopping\")\n",
    "            break\n",
    "\n",
    "print(\"\\nValidation Set Metrics for SpecAugment:\")\n",
    "evaluate_and_report(model_sa, spec_val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d79cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawCNN predicted classes (0-indexed): [0 1 2 3 4]\n",
      "Counts: [234  56   4 316  23]\n"
     ]
    }
   ],
   "source": [
    "# Cell 20a: Which classes does RawCNN predict on the raw‐wave validation set?\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model_raw.eval()\n",
    "raw_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for waves, lengths, accents, genders in val_loader:\n",
    "        waves = waves.to(device)\n",
    "        logits = model_raw(waves)         # RawCNN expects [B, T]\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        raw_preds.extend(preds)\n",
    "\n",
    "raw_preds = np.array(raw_preds)\n",
    "print(\"RawCNN predicted classes (0-indexed):\", np.unique(raw_preds))\n",
    "print(\"Counts:\", np.bincount(raw_preds, minlength=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80e6ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpecCNN predicted classes (0-indexed): [0 1 3 4]\n",
      "Counts: [125 378   0  87  43]\n"
     ]
    }
   ],
   "source": [
    "# Cell 20b: Which classes does SpectrogramCNN predict on the spec‐val set?\n",
    "\n",
    "model_sa.eval()\n",
    "spec_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for specs, lengths, accents, genders in spec_val_loader:\n",
    "        specs = specs.to(device)\n",
    "        logits = model_sa(specs)          # SpecCNN expects [B,1,n_mels,T]\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        spec_preds.extend(preds)\n",
    "\n",
    "spec_preds = np.array(spec_preds)\n",
    "print(\"SpecCNN predicted classes (0-indexed):\", np.unique(spec_preds))\n",
    "print(\"Counts:\", np.bincount(spec_preds, minlength=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618aa64",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbab24e",
   "metadata": {},
   "source": [
    "# Competition submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0beb9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell X: Define a custom collate_fn for the Test set\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads a batch of variable‐length waveforms and returns:\n",
    "      - padded_waves: Tensor [B, T_max]\n",
    "      - lengths      : LongTensor [B]\n",
    "      - filenames    : list[str] of length B\n",
    "    \"\"\"\n",
    "    waves, fnames = zip(*batch)\n",
    "    lengths = torch.tensor([w.shape[0] for w in waves], dtype=torch.long)\n",
    "    padded = pad_sequence(waves, batch_first=True)  # pads with zeros\n",
    "    return padded, lengths, fnames\n",
    "\n",
    "# Re-create your TestAudioDataset (no labels) and DataLoader with the new collate_fn\n",
    "test_ds     = TestAudioDataset(TEST_DIR)\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=test_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0acff6e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m preds, files \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m specs, filenames \u001b[38;5;129;01min\u001b[39;00m spec_test_loader:\n\u001b[1;32m      9\u001b[0m         specs \u001b[38;5;241m=\u001b[39m specs\u001b[38;5;241m.\u001b[39mto(device)             \u001b[38;5;66;03m# [B,1,n_mels,T]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         logits \u001b[38;5;241m=\u001b[39m model_final(specs)          \u001b[38;5;66;03m# OK: 4D input\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell Y: Generate submission.csv from SpectrogramCNN\n",
    "\n",
    "model_final = model_sa  # your SpecAugment‐trained SpectrogramCNN\n",
    "model_final.eval()\n",
    "\n",
    "preds, files = [], []\n",
    "with torch.no_grad():\n",
    "    for specs, filenames in spec_test_loader:\n",
    "        specs = specs.to(device)             # [B,1,n_mels,T]\n",
    "        logits = model_final(specs)          # OK: 4D input\n",
    "        batch_preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        preds.extend([p+1 for p in batch_preds])  # convert to 1–5\n",
    "        files.extend(filenames)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"filename\": files, \"accent\": preds})\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"✅ submission.csv created with {len(df)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ba7ed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpecTest batch: torch.Size([32, 1, 64, 587])\n"
     ]
    }
   ],
   "source": [
    "# Cell Z-1: SpectrogramTestDataset & correct collate_fn\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "\n",
    "class SpectrogramTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads .wav files and returns log-mel-spectrogram + filename.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, mel_transform):\n",
    "        self.paths = sorted(\n",
    "            os.path.join(data_dir, f)\n",
    "            for f in os.listdir(data_dir) if f.endswith('.wav')\n",
    "        )\n",
    "        self.mel = mel_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        wav, sr = torchaudio.load(path)\n",
    "        if sr != 16000:\n",
    "            wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "        wav = (wav - wav.mean()) / (wav.std() + 1e-9)\n",
    "        spec = self.mel(wav)             # [1, n_mels, T]\n",
    "        spec = torch.log(spec + 1e-9)\n",
    "        return spec, os.path.basename(path)\n",
    "\n",
    "def spec_test_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads spectrograms in time to the max length in this batch.\n",
    "    Returns:\n",
    "      - padded_specs: Tensor [B,1,n_mels,T_max]\n",
    "      - filenames    : list[str]\n",
    "    \"\"\"\n",
    "    specs, fnames = zip(*batch)\n",
    "    # find max time dim\n",
    "    T_max = max(s.size(-1) for s in specs)\n",
    "    # pad each spec to T_max\n",
    "    padded = [\n",
    "        torch.nn.functional.pad(s, (0, T_max - s.size(-1)))\n",
    "        for s in specs\n",
    "    ]\n",
    "    padded = torch.stack(padded, dim=0)\n",
    "    return padded, fnames\n",
    "\n",
    "# instantiate loader\n",
    "spec_test_ds     = SpectrogramTestDataset(TEST_DIR, mel_transform)\n",
    "spec_test_loader = DataLoader(\n",
    "    spec_test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=spec_test_collate_fn\n",
    ")\n",
    "print(\"SpecTest batch:\", next(iter(spec_test_loader))[0].shape)  # should be [B,1,n_mels,T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f8b787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission.csv written: 551 rows\n"
     ]
    }
   ],
   "source": [
    "# Cell Z-2: Generate submission.csv from SpectrogramCNN\n",
    "\n",
    "import csv\n",
    "\n",
    "model_final = model_sa  # or model_raw\n",
    "model_final.eval()\n",
    "\n",
    "files, accents = [], []\n",
    "with torch.no_grad():\n",
    "    for specs, fnames in spec_test_loader:\n",
    "        specs = specs.to(device)\n",
    "        logits = model_final(specs)            # shape [B,5]\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        # convert to 1–5\n",
    "        accents.extend([p+1 for p in preds])\n",
    "        files.extend(fnames)\n",
    "\n",
    "# write CSV\n",
    "with open(\"submission.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\", \"accent\"])\n",
    "    for fn, ac in zip(files, accents):\n",
    "        writer.writerow([fn, ac])\n",
    "\n",
    "print(f\"✅ submission.csv written: {len(accents)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98d72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
