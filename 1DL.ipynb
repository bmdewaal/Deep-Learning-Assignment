{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416bf165",
   "metadata": {},
   "source": [
    "# Task 1 - Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f93f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "from glob import glob\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ecd2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Dataset + helpers\n",
    "\n",
    "class AccentAudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lazily loads .wav files and extracts accent & gender from filename.\n",
    "    Filenames like '3f_utterance123.wav' where:\n",
    "      - first char = accent [1-5]\n",
    "      - second char = gender 'm' or 'f'\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.filepaths = sorted(glob(os.path.join(data_dir, '*.wav')))\n",
    "        if not self.filepaths:\n",
    "            raise RuntimeError(f\"[AccentAudioDataset] No .wav files in {data_dir!r}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.filepaths[idx]\n",
    "        waveform, sr = torchaudio.load(path)          # [1, L]\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "        # online standardization\n",
    "        waveform = (waveform - waveform.mean()) / (waveform.std() + 1e-9)\n",
    "        fname = os.path.basename(path)\n",
    "        accent = int(fname[0]) - 1                   # 0–4\n",
    "        gender = 0 if fname[1] == 'm' else 1\n",
    "        return waveform.squeeze(0), accent, gender\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\" Pad to batch-max length, return lengths + labels \"\"\"\n",
    "    waves, accents, genders = zip(*batch)\n",
    "    lengths = torch.tensor([w.size(0) for w in waves], dtype=torch.long)\n",
    "    padded  = pad_sequence(waves, batch_first=True)\n",
    "    return padded, lengths, torch.tensor(accents), torch.tensor(genders)\n",
    "\n",
    "def compute_dataset_stats(data_dir, sample_rate=16000):\n",
    "    \"\"\" Scan WAVs for duration stats; errors if folder’s empty \"\"\"\n",
    "    paths = glob(os.path.join(data_dir, '*.wav'))\n",
    "    if not paths:\n",
    "        raise RuntimeError(f\"[compute_dataset_stats] No .wav files in {data_dir!r}\")\n",
    "    durations = torch.tensor([torchaudio.info(p).num_frames / sample_rate for p in paths])\n",
    "    return {\n",
    "        'count': len(durations),\n",
    "        'min_s':  float(durations.min()),\n",
    "        'max_s':  float(durations.max()),\n",
    "        'mean_s': float(durations.mean()),\n",
    "        'p90_s':  float(durations.kthvalue(int(0.9*len(durations))).values)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec885ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DIR: /Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Train → exists? True\n",
      "  sample files: ['2m_9039.wav', '4f_1887.wav', '4f_9571.wav', '1m_3736.wav', '1m_3078.wav']\n",
      " TEST_DIR: /Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Test → exists? True\n",
      "  sample files: ['9430.wav', '4458.wav', '1534.wav', '8510.wav', '7192.wav']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Point to your folders & verify\n",
    "# ↳ Copy paths exactly, no trailing spaces ↓\n",
    "TRAIN_DIR = \"/Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Train\"\n",
    "TEST_DIR  = \"/Users/bramdewaal/Desktop/Uni/VSC/Deep Learning/Assignment/Test\"\n",
    "\n",
    "# Strip accidental whitespace just in case\n",
    "TRAIN_DIR = TRAIN_DIR.strip()\n",
    "TEST_DIR  = TEST_DIR.strip()\n",
    "\n",
    "print(\"TRAIN_DIR:\", TRAIN_DIR, \"→ exists?\", os.path.isdir(TRAIN_DIR))\n",
    "print(\"  sample files:\", os.listdir(TRAIN_DIR)[:5])\n",
    "print(\" TEST_DIR:\", TEST_DIR, \"→ exists?\", os.path.isdir(TEST_DIR))\n",
    "print(\"  sample files:\", os.listdir(TEST_DIR)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfb1f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch → waves: torch.Size([32, 151552]), lengths: torch.Size([32])\n",
      "Test batch → waves: torch.Size([32, 150186]), lengths: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 (fast sanity check): instantiate datasets, build loaders & grab one batch\n",
    "\n",
    "# 1) Instantiate datasets\n",
    "train_ds = AccentAudioDataset(TRAIN_DIR)\n",
    "test_ds  = AccentAudioDataset(TEST_DIR)\n",
    "\n",
    "# 2) Create DataLoaders with num_workers=0 to avoid spawn overhead in Jupyter\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,       # no worker processes\n",
    "    pin_memory=False,    # lower overhead in notebook\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# 3) Sanity-check one batch from each loader\n",
    "for name, loader in [(\"Train\", train_loader), (\"Test\", test_loader)]:\n",
    "    waves, lengths, accents, genders = next(iter(loader))\n",
    "    print(f\"{name} batch → waves: {waves.shape}, lengths: {lengths.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132bc6d",
   "metadata": {},
   "source": [
    "# Task 2 - Raw signal 1d cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed42808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Raw-Signal 1D CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RawCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    1D CNN for raw waveform classification (5 accents).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=5, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Conv stage 1: 1→16 channels, downsample by 4\n",
    "            nn.Conv1d(1, 16, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),  # seq_len / 4 total\n",
    "\n",
    "            # Conv stage 2: 16→32, downsample by 2\n",
    "            nn.Conv1d(16, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),  # seq_len / 8 total\n",
    "\n",
    "            # Conv stage 3: 32→64, downsample by 2\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),  # seq_len / 16 total\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1),  # collapse time dim\n",
    "            nn.Flatten(),             # → [B, 64]\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: FloatTensor [B, T] raw wave\n",
    "        \"\"\"\n",
    "        # add channel dim\n",
    "        x = x.unsqueeze(1)  # [B,1,T]\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c140765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "✅ RawCNN forward pass on mps OK: torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Device selection & forward pass test (using MPS if available)\n",
    "\n",
    "import torch\n",
    "\n",
    "# 1) Select device: MPS (Apple GPU) if available, else CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2) Move model to device\n",
    "model = RawCNN(num_classes=5, dropout=0.2).to(device)\n",
    "model.eval()\n",
    "\n",
    "# 3) Grab one batch, move to device, and test forward pass\n",
    "with torch.no_grad():\n",
    "    waves, lengths, accents, genders = next(iter(train_loader))\n",
    "    waves = waves.to(device)\n",
    "    logits = model(waves)\n",
    "    assert logits.shape == (waves.size(0), 5), f\"Expected [B,5], got {logits.shape}\"\n",
    "    print(f\"✅ RawCNN forward pass on {device} OK: {logits.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcfb5c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   → loss: 1.5560, acc: 0.319, time: 53.7s\n",
      "Validate→ loss: 0.8815, acc: 0.107\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training & Evaluation Functions with MPS Support\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "    for waves, lengths, accents, _ in loader:\n",
    "        waves, accents = waves.to(device), accents.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(waves)\n",
    "        loss = F.cross_entropy(logits, accents)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * waves.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == accents).sum().item()\n",
    "        total += waves.size(0)\n",
    "    elapsed = time.time() - start\n",
    "    return total_loss / total, correct / total, elapsed\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for waves, lengths, accents, _ in loader:\n",
    "        waves, accents = waves.to(device), accents.to(device)\n",
    "        logits = model(waves)\n",
    "        loss = F.cross_entropy(logits, accents)\n",
    "\n",
    "        total_loss += loss.item() * waves.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == accents).sum().item()\n",
    "        total += waves.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# Quick function test (one batch)\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = RawCNN(num_classes=5, dropout=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_loss, train_acc, train_time = train_one_epoch(model, train_loader, optimizer, device)\n",
    "val_loss,   val_acc   = evaluate(model, test_loader, device)\n",
    "print(f\"Train   → loss: {train_loss:.4f}, acc: {train_acc:.3f}, time: {train_time:.1f}s\")\n",
    "print(f\"Validate→ loss: {val_loss:.4f}, acc: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f71af6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.4941, Acc: 0.384 | Val   Loss: 0.8813, Acc: 0.109 | Time: 21.1s\n",
      "Epoch 02 | Train Loss: 1.4381, Acc: 0.418 | Val   Loss: 0.8987, Acc: 0.107 | Time: 15.2s\n",
      "Epoch 03 | Train Loss: 1.3776, Acc: 0.439 | Val   Loss: 0.9240, Acc: 0.096 | Time: 15.5s\n",
      "Epoch 04 | Train Loss: 1.3358, Acc: 0.459 | Val   Loss: 0.9336, Acc: 0.105 | Time: 12.9s\n",
      "⏹ Early stopping at epoch 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Full Training Loop with Scheduler & Early Stopping\n",
    "\n",
    "num_epochs = 5\n",
    "patience = 2\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Scheduler: halve LR when val loss plateaus\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='min',\n",
    "                                                       factor=0.5,\n",
    "                                                       patience=1)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start = time.time()\n",
    "    train_loss, train_acc, train_time = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, device)\n",
    "    scheduler.step(val_loss)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.3f} | \"\n",
    "          f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.3f} | \"\n",
    "          f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve > patience:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b440833",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68f0dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram batch → torch.Size([32, 1, 64, 608]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Spectrogram Dataset & DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Mel-spectrogram transform\n",
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=16000, n_fft=512, hop_length=256, n_mels=64\n",
    ")\n",
    "\n",
    "class SpectrogramDataset(AccentAudioDataset):\n",
    "    def __init__(self, data_dir, mel_transform):\n",
    "        super().__init__(data_dir)\n",
    "        self.mel_transform = mel_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, accent, gender = super().__getitem__(idx)\n",
    "        spec = self.mel_transform(waveform.unsqueeze(0))  # [1, n_mels, frames]\n",
    "        spec = torch.log(spec + 1e-9)\n",
    "        return spec, accent, gender\n",
    "\n",
    "def spectrogram_collate_fn(batch):\n",
    "    specs, accents, genders = zip(*batch)\n",
    "    lengths = torch.tensor([s.size(2) for s in specs], dtype=torch.long)\n",
    "    T_max = lengths.max().item()\n",
    "    padded = [F.pad(s, (0, T_max - s.size(2))) for s in specs]\n",
    "    padded = torch.stack(padded)  # [B,1,n_mels,T_max]\n",
    "    return padded, lengths, torch.tensor(accents), torch.tensor(genders)\n",
    "\n",
    "# Instantiate loaders\n",
    "spec_train_ds = SpectrogramDataset(TRAIN_DIR, mel_transform)\n",
    "spec_test_ds  = SpectrogramDataset(TEST_DIR,  mel_transform)\n",
    "\n",
    "spec_train_loader = DataLoader(\n",
    "    spec_train_ds, batch_size=32, shuffle=True,\n",
    "    num_workers=0, pin_memory=False,\n",
    "    collate_fn=spectrogram_collate_fn\n",
    ")\n",
    "spec_test_loader = DataLoader(\n",
    "    spec_test_ds, batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=False,\n",
    "    collate_fn=spectrogram_collate_fn\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "specs, lengths, accents, genders = next(iter(spec_train_loader))\n",
    "print(\"Spectrogram batch →\", specs.shape, lengths.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27169fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SpectrogramCNN forward: torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Spectrogram CNN Definition & Forward Test\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Forward‐pass test on MPS/CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = SpectrogramCNN().to(device)\n",
    "with torch.no_grad():\n",
    "    specs = specs.to(device)\n",
    "    logits = model(specs)\n",
    "    print(\"✅ SpectrogramCNN forward:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a73262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "SpectrogramCNN → Train loss: 1.5379, acc: 0.316\n",
      "                 Val   loss: 0.9028, acc: 0.109\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Train & Eval SpectrogramCNN on MPS/CPU (one‐batch smoke test)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1) Device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2) Instantiate model, optimizer\n",
    "model_spec = SpectrogramCNN(num_classes=5, dropout=0.3).to(device)\n",
    "optimizer_spec = optim.Adam(model_spec.parameters(), lr=1e-3)\n",
    "\n",
    "# 3) Quick one‐batch train & eval\n",
    "train_loss, train_acc, _ = train_one_epoch(model_spec, spec_train_loader, optimizer_spec, device)\n",
    "val_loss,   val_acc       = evaluate   (model_spec, spec_test_loader,        device)\n",
    "\n",
    "print(f\"SpectrogramCNN → Train loss: {train_loss:.4f}, acc: {train_acc:.3f}\")\n",
    "print(f\"                 Val   loss: {val_loss:.4f}, acc: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03baeb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.4207, Acc: 0.424 | Val   Loss: 0.9557, Acc: 0.123 | Time: 16.5s\n",
      "Epoch 02 | Train Loss: 1.3080, Acc: 0.485 | Val   Loss: 1.2023, Acc: 0.102 | Time: 15.4s\n",
      "Epoch 03 | Train Loss: 1.2394, Acc: 0.516 | Val   Loss: 0.9736, Acc: 0.132 | Time: 13.1s\n",
      "Epoch 04 | Train Loss: 1.1719, Acc: 0.549 | Val   Loss: 1.0695, Acc: 0.114 | Time: 14.1s\n",
      "⏹ Early stopping at epoch 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Full Training Loop for SpectrogramCNN with Scheduler & Early Stopping\n",
    "\n",
    "num_epochs = 5\n",
    "patience   = 2\n",
    "best_val   = float('inf')\n",
    "no_improve = 0\n",
    "\n",
    "# Scheduler to reduce LR on plateau\n",
    "scheduler_spec = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_spec, mode='min', factor=0.5, patience=1\n",
    ")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc, tr_time = train_one_epoch(\n",
    "        model_spec, spec_train_loader, optimizer_spec, device\n",
    "    )\n",
    "    vl_loss, vl_acc = evaluate(model_spec, spec_test_loader, device)\n",
    "    scheduler_spec.step(vl_loss)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.3f} | \"\n",
    "          f\"Val   Loss: {vl_loss:.4f}, Acc: {vl_acc:.3f} | \"\n",
    "          f\"Time: {dt:.1f}s\")\n",
    "\n",
    "    # early stopping\n",
    "    if vl_loss < best_val - 1e-4:\n",
    "        best_val   = vl_loss\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve > patience:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0255d",
   "metadata": {},
   "source": [
    "# Task 3 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6f40232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do=0.1, wd=0.0 → val_acc=0.098\n",
      "do=0.1, wd=0.0001 → val_acc=0.127\n",
      "do=0.1, wd=0.001 → val_acc=0.118\n",
      "do=0.3, wd=0.0 → val_acc=0.123\n",
      "do=0.3, wd=0.0001 → val_acc=0.123\n",
      "do=0.3, wd=0.001 → val_acc=0.131\n",
      "do=0.5, wd=0.0 → val_acc=0.127\n",
      "do=0.5, wd=0.0001 → val_acc=0.114\n",
      "do=0.5, wd=0.001 → val_acc=0.103\n",
      "   dropout  weight_decay   val_acc  train_acc\n",
      "0      0.1        0.0000  0.098004   0.589387\n",
      "1      0.1        0.0001  0.127042   0.598863\n",
      "2      0.1        0.0010  0.117967   0.567593\n",
      "3      0.3        0.0000  0.123412   0.512634\n",
      "4      0.3        0.0001  0.123412   0.550221\n",
      "5      0.3        0.0010  0.130672   0.532217\n",
      "6      0.5        0.0000  0.127042   0.456412\n",
      "7      0.5        0.0001  0.114338   0.456728\n",
      "8      0.5        0.0010  0.103448   0.475995\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Regularization Experiments on SpectrogramCNN\n",
    "\n",
    "import itertools\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameter grid\n",
    "dropouts     = [0.1, 0.3, 0.5]\n",
    "weight_decays = [0.0, 1e-4, 1e-3]\n",
    "\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "for do, wd in itertools.product(dropouts, weight_decays):\n",
    "    # 1) Instantiate model & optimizer with wd\n",
    "    model = SpectrogramCNN(num_classes=5, dropout=do).to(device)\n",
    "    optim_spec = optim.Adam(model.parameters(), lr=1e-3, weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optim_spec, mode='min', factor=0.5, patience=1\n",
    "    )\n",
    "\n",
    "    # 2) Train with early stopping for up to 5 epochs\n",
    "    best_val = float('inf')\n",
    "    no_improve = 0\n",
    "    for epoch in range(1, 6):\n",
    "        tr_loss, tr_acc, _ = train_one_epoch(model, spec_train_loader, optim_spec, device)\n",
    "        vl_loss, vl_acc    = evaluate(model, spec_test_loader,       device)\n",
    "        scheduler.step(vl_loss)\n",
    "        if vl_loss < best_val - 1e-4:\n",
    "            best_val, no_improve = vl_loss, 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        if no_improve > 2:\n",
    "            break\n",
    "\n",
    "    # 3) Record final val accuracy & time/epoch ~ from spec loop timings\n",
    "    results.append({\n",
    "        'dropout': do,\n",
    "        'weight_decay': wd,\n",
    "        'val_acc': vl_acc,\n",
    "        'train_acc': tr_acc\n",
    "    })\n",
    "    print(f\"do={do}, wd={wd} → val_acc={vl_acc:.3f}\")\n",
    "\n",
    "# 4) Tabulate results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6431be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RawCNN] Epoch 01 | Train Loss: 1.5760, Acc: 0.293 | Val   Loss: 0.8870, Acc: 0.096 | Time: 30.2s\n",
      "[RawCNN] Epoch 02 | Train Loss: 1.5160, Acc: 0.368 | Val   Loss: 0.8812, Acc: 0.103 | Time: 14.6s\n",
      "[RawCNN] Epoch 03 | Train Loss: 1.4589, Acc: 0.409 | Val   Loss: 0.9016, Acc: 0.123 | Time: 15.2s\n",
      "[RawCNN] Epoch 04 | Train Loss: 1.4146, Acc: 0.423 | Val   Loss: 0.8882, Acc: 0.107 | Time: 15.3s\n",
      "[RawCNN] Epoch 05 | Train Loss: 1.3691, Acc: 0.438 | Val   Loss: 0.9064, Acc: 0.116 | Time: 15.0s\n",
      "⏹ Early stopping at epoch 5\n",
      "✔️ Finished RawCNN training: best val_acc = 0.116\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Train RawCNN with Best Regularization & Early Stopping\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparams from SpectrogramCNN grid: dropout=0.3, weight_decay=1e-3\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model_raw = RawCNN(num_classes=5, dropout=0.3).to(device)\n",
    "optimizer_raw = optim.Adam(model_raw.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler_raw = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_raw, mode='min', factor=0.5, patience=1\n",
    ")\n",
    "\n",
    "# Training loop (up to 5 epochs, patience=2)\n",
    "num_epochs = 5\n",
    "patience   = 2\n",
    "best_val   = float('inf')\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc, tr_time = train_one_epoch(\n",
    "        model_raw, train_loader, optimizer_raw, device\n",
    "    )\n",
    "    vl_loss, vl_acc = evaluate(model_raw, test_loader, device)\n",
    "    scheduler_raw.step(vl_loss)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(f\"[RawCNN] Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.3f} | \"\n",
    "          f\"Val   Loss: {vl_loss:.4f}, Acc: {vl_acc:.3f} | \"\n",
    "          f\"Time: {dt:.1f}s\")\n",
    "\n",
    "    # Early stopping\n",
    "    if vl_loss < best_val - 1e-4:\n",
    "        best_val, no_improve = vl_loss, 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve > patience:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"✔️ Finished RawCNN training: best val_acc = {vl_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccd785dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Accents):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 9, does not match size of target_names, 5. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 1) Overall report\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report (Accents):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\n\u001b[1;32m     24\u001b[0m     all_labels, all_preds,\n\u001b[1;32m     25\u001b[0m     target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m)]\n\u001b[1;32m     26\u001b[0m ))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 2) Confusion Matrix\u001b[39;00m\n\u001b[1;32m     29\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(all_labels, all_preds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2329\u001b[0m             )\n\u001b[1;32m   2330\u001b[0m         )\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2336\u001b[0m         )\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 9, does not match size of target_names, 5. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Cell 15: Detailed Performance Evaluation by Accent & Gender\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "model_raw.eval()\n",
    "all_preds, all_labels, all_genders = [], [], []\n",
    "with torch.no_grad():\n",
    "    for waves, lengths, accents, genders in test_loader:\n",
    "        waves = waves.to(device)\n",
    "        logits = model_raw(waves)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(accents.numpy())\n",
    "        all_genders.append(genders.numpy())\n",
    "\n",
    "all_preds   = np.concatenate(all_preds)\n",
    "all_labels  = np.concatenate(all_labels)\n",
    "all_genders = np.concatenate(all_genders)\n",
    "\n",
    "# 1) Overall report\n",
    "print(\"Classification Report (Accents):\")\n",
    "print(classification_report(\n",
    "    all_labels, all_preds,\n",
    "    target_names=[f\"Accent {i}\" for i in range(1,6)]\n",
    "))\n",
    "\n",
    "# 2) Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 3) Gender‐specific accuracy\n",
    "for gender_val, gender_name in zip([0,1], [\"Male\",\"Female\"]):\n",
    "    idxs = all_genders == gender_val\n",
    "    acc = (all_preds[idxs] == all_labels[idxs]).mean()\n",
    "    print(f\"{gender_name} accuracy: {acc:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ea7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
