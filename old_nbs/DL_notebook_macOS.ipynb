{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad517c19",
   "metadata": {},
   "source": [
    "# Group assignment DL - Accent classification\n",
    "\n",
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd92b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch\n",
    "# %pip install -r requirements.txt \n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1935806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bramdewaal/anaconda3/lib/python3.11/site-packages/colorcorrect-0.9.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchaudio in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: torch==2.7.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torchaudio) (2.7.0)\n",
      "Requirement already satisfied: filelock in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchaudio) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchaudio) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchaudio) (2023.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.7.0->torchaudio) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd294bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch, torchaudio\n",
    "print(torch.__version__, torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0c8f9",
   "metadata": {},
   "source": [
    "## FIX FIX FIXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d051fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.0\n",
      "Uninstalling torch-2.7.0:\n",
      "  Successfully uninstalled torch-2.7.0\n",
      "Found existing installation: torchvision 0.22.0\n",
      "Uninstalling torchvision-0.22.0:\n",
      "  Successfully uninstalled torchvision-0.22.0\n",
      "Found existing installation: torchaudio 2.7.0\n",
      "Uninstalling torchaudio-2.7.0:\n",
      "  Successfully uninstalled torchaudio-2.7.0\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/bramdewaal/anaconda3/lib/python3.11/site-packages/colorcorrect-0.9.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_directml as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch_directml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d73c868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bramdewaal/anaconda3/lib/python3.11/site-packages/colorcorrect-0.9.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch-directml (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-directml\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch-directml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0c5e7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bramdewaal/anaconda3/lib/python3.11/site-packages/colorcorrect-0.9.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchvision\n",
      "  Using cached torchvision-0.22.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.4)\n",
      "Collecting torch==2.7.0 (from torchvision)\n",
      "  Using cached torch-2.7.0-cp311-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.7.0->torchvision) (2.1.3)\n",
      "Using cached torchvision-0.22.0-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached torch-2.7.0-cp311-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached torchaudio-2.7.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e1a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7daa5748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bramdewaal/anaconda3/bin/python\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# Are you really on your venv kernel?\n",
    "import sys; print(sys.executable)\n",
    "\n",
    "# Is your model/tensor on the DirectML device?\n",
    "x = torch.randn(10, device=device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc157e77",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a562eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install https://files.pythonhosted.org/packages/…/torch_directml-0.2.5.dev240914-cp311-cp311-win_amd64.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae6fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bramdewaal/anaconda3/lib/python3.11/site-packages/colorcorrect-0.9.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.7.0)\n",
      "Requirement already satisfied: numpy in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.24.4)\n",
      "Requirement already satisfied: torchaudio in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.7.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3fe4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata(data_dir: str):\n",
    "    \"\"\"\n",
    "    Analyzing and collecting all metadata from the audio files (gender, male or female)\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for fname in files:\n",
    "            if fname.lower().endswith(\".wav\"):\n",
    "                path = os.path.join(root, fname)\n",
    "                accent = int(fname[0])          # '1'–'5'\n",
    "                gender = fname[1].lower()       # 'm' or 'f'\n",
    "                records.append({\"path\": path, \"accent\": accent, \"gender\": gender})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "class AccentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading, preprocessing, and feature-extracting audio.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        metadata_df: pd.DataFrame,\n",
    "        approach: str = \"raw\",  # \"raw\" or \"mel\"\n",
    "        max_length: int = 16000 * 5,  # 5 seconds\n",
    "        sample_rate: int = 16000,\n",
    "        transform: torch.nn.Module = None,\n",
    "        target_transform = None\n",
    "    ):\n",
    "        self.df = metadata_df.reset_index(drop=True)\n",
    "        self.approach = approach\n",
    "        self.max_length = max_length\n",
    "        self.sample_rate = sample_rate\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # Silence trimming (VAD)\n",
    "        self.vad = torchaudio.transforms.Vad(sample_rate=sample_rate)\n",
    "\n",
    "        # Feature transforms (for 'mel' approach)\n",
    "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mels=64,\n",
    "            n_fft=1024,\n",
    "            hop_length=512\n",
    "        )\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        waveform, sr = torchaudio.load(row[\"path\"])\n",
    "\n",
    "        # Resample if needed\n",
    "        if sr != self.sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(sr, self.sample_rate)(waveform)\n",
    "\n",
    "        # Convert to mono\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        # Trim leading/trailing silence\n",
    "        waveform = self.vad(waveform)\n",
    "\n",
    "        # Pad or truncate to fixed length\n",
    "        length = waveform.size(1)\n",
    "        if length < self.max_length:\n",
    "            pad_amt = self.max_length - length\n",
    "            waveform = F.pad(waveform, (0, pad_amt))\n",
    "        else:\n",
    "            waveform = waveform[:, :self.max_length]\n",
    "\n",
    "        # Per-sample normalization\n",
    "        waveform = (waveform - waveform.mean()) / (waveform.std() + 1e-9)\n",
    "\n",
    "        # Optional augmentations\n",
    "        if self.transform is not None:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        # Feature extraction\n",
    "        if self.approach == \"raw\":\n",
    "            features = waveform  # shape: [1, max_length]\n",
    "        elif self.approach == \"mel\":\n",
    "            mel_spec = self.mel_spectrogram(waveform)\n",
    "            features = self.db_transform(mel_spec)  # shape: [1, n_mels, time_steps]\n",
    "        else:\n",
    "            raise ValueError(\"approach must be 'raw' or 'mel'\")\n",
    "\n",
    "        label = row[\"accent\"]\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbe1cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "207d8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "414345d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bramdewaal/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb995b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_metadata( \"Train\" ) # Training dataframe based on accent & gender metadata\n",
    "raw_ds = AccentDataset(df, approach=\"raw\",  max_length=16000*5)\n",
    "mel_ds = AccentDataset(df, approach=\"mel\",  max_length=16000*5)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 128\n",
    "raw_loader = DataLoader(raw_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "mel_loader = DataLoader(mel_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af46559",
   "metadata": {},
   "source": [
    "## 1.2a: Raw input signal -> analyze as 1D signal -> standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe1b94f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bramdewaal/anaconda3/lib/python3.11/site-packages/colorcorrect-0.9.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bramdewaal/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "485089f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting into train/val (80/20) with stratification on accent, so they each appear ~ in the same proportion in train/validation set\n",
    "val_fraction = 0.2\n",
    "df_train, df_val = train_test_split(\n",
    "    df,\n",
    "    test_size=val_fraction,\n",
    "    random_state=42,\n",
    "    stratify=df[\"accent\"]\n",
    ")\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val   = df_val.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "max_length = 16000 * 5  # 5 seconds\n",
    "batch_size = 32\n",
    "num_workers = 8\n",
    "\n",
    "# Raw waveform datasets and loaders\n",
    "train_ds = AccentDataset(\n",
    "    metadata_df=df_train,\n",
    "    approach=\"raw\",       # raw 1D signal\n",
    "    max_length=max_length,\n",
    ")\n",
    "val_ds   = AccentDataset(\n",
    "    metadata_df=df_val,\n",
    "    approach=\"raw\",\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1bbaf",
   "metadata": {},
   "source": [
    "## Raw models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb9ca5",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ce09e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DirectML unavailable—using CPU: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    import torch_directml\n",
    "    device = torch_directml.device()\n",
    "    print(\"Using DirectML on AMD GPU:\", device)\n",
    "except ImportError:\n",
    "    import torch\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"DirectML unavailable—using CPU:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5c340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48837ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "             # ← add this\n",
    "\n",
    "# --- 1. Define RNN and LSTM models ---\n",
    "\n",
    "\n",
    "class RawCNN1D(nn.Module):\n",
    "    def __init__(self, num_classes=5, p_dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=9, stride=1, padding=4), nn.ReLU(),\n",
    "            nn.MaxPool1d(4),    # <-- aggressive pooling (downsample x4)\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=9, stride=1, padding=4), nn.ReLU(),\n",
    "            nn.MaxPool1d(4),    # <-- downsample again (x4)\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=9, stride=1, padding=4), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),  # Final collapse to [B, 128, 1]\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p_dropout)\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return self.classifier(out)\n",
    "\n",
    "\n",
    "class MelCNN2D(nn.Module):\n",
    "    def __init__(self, num_classes=5, p_dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p_dropout)\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 1, n_mels, time]\n",
    "        out = self.net(x)\n",
    "        return self.classifier(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff8211",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96af18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.AccentDataset object at 0x3397e1dd0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_ds_raw = AccentDataset(df_train, approach=\"raw\", max_length=16000*5)\n",
    "val_ds_raw   = AccentDataset(df_val, approach=\"raw\", max_length=16000*5)\n",
    "\n",
    "# Raw loaders\n",
    "train_loader_raw = DataLoader(train_ds_raw, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader_raw   = DataLoader(val_ds_raw, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "# Mel spectogram loaders \n",
    "train_ds_mel = AccentDataset(df_train, approach=\"mel\", max_length=16000*5)\n",
    "val_ds_mel   = AccentDataset(df_val, approach=\"mel\", max_length=16000*5)\n",
    "\n",
    "train_loader_mel = DataLoader(train_ds_mel, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader_mel   = DataLoader(val_ds_mel, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c0f514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS on Apple Silicon: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Selecting device, as training was done on both AMD GPU and Apple Sillicon chip\n",
    "try:\n",
    "    import torch_directml\n",
    "    device = torch_directml.device()\n",
    "    print(\"Using DirectML on AMD GPU:\", device)\n",
    "\n",
    "except ImportError:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using Apple MPS on Apple Silicon:\", device)\n",
    "    else:\n",
    "        # Fallback to CPU\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Falling back to CPU:\", device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def run_experiment(model_cls, train_loader, val_loader, epochs=10, **model_kwargs):\n",
    "    model = model_cls(**model_kwargs).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    print(f\"Training {model_cls.__name__} for {epochs} epochs...\\n\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # Train\n",
    "        model.train()\n",
    "        total_loss, correct, count = 0, 0, 0\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            print(f\"Processing batch {batch_idx+1}/{len(train_loader)}\")\n",
    "            x, y = x.to(device, non_blocking=True), (y-1).to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            count += x.size(0)\n",
    "\n",
    "        train_loss = total_loss / count\n",
    "        train_acc = correct / count\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        total_loss, correct, count = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device, non_blocking=True), (y-1).to(device, non_blocking=True)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                count += x.size(0)\n",
    "\n",
    "        val_loss = total_loss / count\n",
    "        val_acc = correct / count\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        print(f\"[{model_cls.__name__}] Epoch {epoch:02d}/{epochs} \"\n",
    "              f\"Train: loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
    "              f\"Val: loss={val_loss:.4f}, acc={val_acc:.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "    print(\"\\nTraining finished.\\n\")\n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d75159e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'code_framelocals_names' from 'torch._C._dynamo.eval_frame' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Running the experiments\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Training CNN1D on raw waveforms\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m raw_cnn_model, raw_cnn_history \u001b[38;5;241m=\u001b[39m run_experiment(\n\u001b[1;32m      4\u001b[0m     RawCNN1D,\n\u001b[1;32m      5\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader_raw,\n\u001b[1;32m      6\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mval_loader_raw,\n\u001b[1;32m      7\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      8\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      9\u001b[0m     p_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
      "Cell \u001b[0;32mIn[34], line 26\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model_cls, train_loader, val_loader, epochs, **model_kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_experiment\u001b[39m(model_cls, train_loader, val_loader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs):\n\u001b[1;32m     25\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 26\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     27\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     29\u001b[0m     history \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:99\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m betas[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor betas[1] must be 1-element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     88\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     89\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m     90\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     91\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m     92\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     93\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m     94\u001b[0m     foreach\u001b[38;5;241m=\u001b[39mforeach,\n\u001b[1;32m     95\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     96\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m     97\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[1;32m     98\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m---> 99\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params, defaults)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:377\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:  \u001b[38;5;66;03m# noqa: D105\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefaults\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults,\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate,\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_groups\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups,\n\u001b[1;32m    381\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_compile.py:27\u001b[0m, in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_disable_dynamo\u001b[39m(\n\u001b[1;32m     23\u001b[0m     fn: Literal[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, recursive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[Callable[_P, _T]], Callable[_P, _T]]: \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_disable_dynamo\u001b[39m(\n\u001b[1;32m     28\u001b[0m     fn: Optional[Callable[_P, _T]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, recursive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Callable[_P, _T], Callable[[Callable[_P, _T]], Callable[_P, _T]]]:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    This API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    torch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    the invocation of the decorated function.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:57\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     58\u001b[0m     config,\n\u001b[1;32m     59\u001b[0m     exc,\n\u001b[1;32m     60\u001b[0m     graph_break_hints,\n\u001b[1;32m     61\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[1;32m     62\u001b[0m     trace_rules,\n\u001b[1;32m     63\u001b[0m     variables,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     66\u001b[0m     get_indexof,\n\u001b[1;32m     67\u001b[0m     JUMP_OPNAMES,\n\u001b[1;32m     68\u001b[0m     livevars_analysis,\n\u001b[1;32m     69\u001b[0m     propagate_line_nums,\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     72\u001b[0m     cleaned_instructions,\n\u001b[1;32m     73\u001b[0m     create_call_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     unique_id,\n\u001b[1;32m     81\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     BuiltinVariable,\n\u001b[1;32m     34\u001b[0m     FunctionalCallVariable,\n\u001b[1;32m     35\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     36\u001b[0m     LocalGeneratorFunctionVariable,\n\u001b[1;32m     37\u001b[0m     LocalGeneratorObjectVariable,\n\u001b[1;32m     38\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     39\u001b[0m     PolyfilledFunctionVariable,\n\u001b[1;32m     40\u001b[0m     SkipFunctionVariable,\n\u001b[1;32m     41\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[1;32m     42\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     43\u001b[0m     UserMethodVariable,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     47\u001b[0m np: Optional[types\u001b[38;5;241m.\u001b[39mModuleType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py:19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/variables/base.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcurrent_scope_id\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m current_scope_id\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unimplemented, unimplemented_v2\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrSource, Source\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cmp_name_to_op_mapping, istype\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/guards.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_device\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_framelocals_names\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m     check_obj_id,\n\u001b[1;32m     49\u001b[0m     check_type_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     RootGuardManager,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     IndexedSource,\n\u001b[1;32m     61\u001b[0m     is_from_flatten_script_object_source,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     TensorPropertySource,\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'code_framelocals_names' from 'torch._C._dynamo.eval_frame' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Running the experiments\n",
    "# Training CNN1D on raw waveforms\n",
    "raw_cnn_model, raw_cnn_history = run_experiment(\n",
    "    RawCNN1D,\n",
    "    train_loader=train_loader_raw,\n",
    "    val_loader=val_loader_raw,\n",
    "    epochs=5,\n",
    "    num_classes=5,\n",
    "    p_dropout=0.3\n",
    ")\n",
    "# Five epochs for training on raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "2532\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_raw))   # How many batches per epoch?\n",
    "print(len(train_ds_raw))       # How many total samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d540136",
   "metadata": {},
   "source": [
    "## Analysing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e420eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bram\\documents\\github\\deep-learning-assignment\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(history, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plots train/validation loss and accuracy curves for a model.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "    # Plot Loss\n",
    "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    ax1.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    ax1.set_title(f\"{model_name} Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    ax2.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    ax2.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    ax2.set_title(f\"{model_name} Accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.suptitle(f\"Training Curves for {model_name}\", fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f902f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_curves(raw_cnn_history, model_name=\"Raw CNN1D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439623e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training CNN2D on Mel spectrograms\n",
    "# mel_cnn_model, mel_cnn_history = run_experiment(\n",
    "#     MelCNN2D,\n",
    "#     train_loader=train_loader_mel,\n",
    "#     val_loader=val_loader_mel,\n",
    "#     num_classes=5,\n",
    "#     p_dropout=0.3\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5eb2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_curves(mel_cnn_history, model_name=\"Mel CNN2D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
